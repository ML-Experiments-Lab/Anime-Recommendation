# -*- coding: utf-8 -*-
"""Anime_Recommendation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/ishitaganatra/anime-recommendation.07ed8afe-f30b-479c-bc1d-a22c0655c1b1.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250504/auto/storage/goog4_request%26X-Goog-Date%3D20250504T125255Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D390e6b954423a6be0661b68a29c244760b8e8f66b6989cc203b4dabe2dc8a68993c1a012ead899ba41562a7729caa08140556e613f2b64c70e0cf990cf648e6da74c0262479e0049ee2d69e3fb71ba39ac50c2ea130cfb617b85f88dbb61642b6531af5b44e6f66ea01560d665a1b0d5339b6363c528f3530eacc18c6873beb643b78667b2cf03111c45336487a9ccd1beb2fee917a2e8b0260ae1e0ba95ee604f41df72d990d8b82b3440d2ed5310575bae2e893686edf697db97b5a3bfcae330d8b3febbbdb8f89871914fcdb16eefcda0cacb37b1b6767f641d50eb6bd64a4249316986ec111eb86efb91b1d1397086e69d0a6d8dfe42c35a5ad630c4bdd8
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
yashnarnaware_anime_dataset_2024_path = kagglehub.dataset_download('yashnarnaware/anime-dataset-2024')

print('Data source import complete.')

import numpy as np
import pandas as pd

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import re
import nltk
from nltk.stem.porter import PorterStemmer
from sklearn.preprocessing import MinMaxScaler
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics.pairwise import cosine_similarity
from fuzzywuzzy import process
from IPython.display import Image, display

anime = pd.read_csv("static/anime_dataset.csv")

anime.head()

anime.info()

anime.shape

anime.isnull().sum()

anime['English Name'] = anime['English Name'].fillna('Unknown')

anime['Producers'] = anime['Producers'].fillna('Unknown')

anime['Theme'] = anime['Theme'].fillna('Unknown')

anime['Rating'] = anime['Rating'].fillna(anime['Rating'].mean())

anime['Genres'] = anime['Genres'].fillna('Unknown')

anime['Duration'] = anime['Duration'].fillna('Unknown')

anime['Synopsis'] = anime['Synopsis'].fillna('Synopsis is not available')

anime['Image source'] = anime['Image source'].fillna('Image preview not available')

new_anime = anime[['Name', 'Synopsis', 'Genres', 'English Name', 'Image source', 'Rating', 'Duration', 'Theme', 'Producers']]

new_anime.duplicated().sum()

ps = PorterStemmer()

def stem(text):
    y = []
    for i in text.split():
        y.append(ps.stem(i))

    return " ".join(y)

text_columns = ['Genres', 'Synopsis', 'Theme', 'Producers']

for col in text_columns:
    new_anime[col] = new_anime[col].apply(lambda x: stem(x) if isinstance(x, str) else x)

def convert_duration(duration):
    try:
        # Check if the duration includes 'hr' and 'min'
        if 'hr' in duration or 'min' in duration:
            hours = re.search(r'(\d+)\s*hr', duration)
            minutes = re.search(r'(\d+)\s*min', duration)

            # Convert hours and minutes to total minutes
            total_minutes = (int(hours.group(1)) * 60 if hours else 0) + (int(minutes.group(1)) if minutes else 0)
            return total_minutes

        # If it includes 'sec', treat it as negligible and return 1 minute
        elif 'sec' in duration:
            return 1

        # If only 'min' is present
        elif 'min' in duration:
            minutes = re.search(r'(\d+)\s*min', duration)
            return int(minutes.group(1)) if minutes else 0

        # If format is unrecognized
        else:
            return 0

    except:
        return 0

new_anime['Duration'] = new_anime['Duration'].apply(convert_duration)

scaler = MinMaxScaler()
numerical_columns = ['Rating', 'Duration']
new_anime[numerical_columns] = scaler.fit_transform(new_anime[numerical_columns])

new_anime['combined_features'] = ((new_anime['Genres'] + " ")*15 + (new_anime['Synopsis'] + " ")*5 + (new_anime['Producers'] + " ")*6 + (new_anime['Theme']  + " ")*13 + (new_anime['Rating'].astype(str) + " ")*15 + (new_anime['Duration'].astype(str) + " ")*13)

tfidf = TfidfVectorizer(stop_words='english', max_features=5000)

tfidf_matrix = tfidf.fit_transform(new_anime['combined_features'])

nn_model = NearestNeighbors(metric='cosine', algorithm='brute')
nn_model.fit(tfidf_matrix)

def recommend(movie_name, top_n=20):

    movie_name = movie_name.strip().lower()

    best_match = process.extractOne(movie_name, new_anime['English Name'])
    if best_match is None or best_match[1] < 80:  # Match score threshold
        print("Anime not found in the dataset.")
        return

    anime_index = new_anime[new_anime['English Name'] == best_match[0]].index[0]
    distances, indices = nn_model.kneighbors(tfidf_matrix[anime_index], n_neighbors=50)

    print(f"Recommendations for '{movie_name}':\n")
    recommendations = 0
    i = 0  # Start from the first neighbor (after the query itself)

    while recommendations < top_n and i < len(indices[0]):
        recommended_anime = anime.iloc[indices[0][i]]

        # Skip if 'Unknown' or invalid recommendation
        if recommended_anime['English Name'] == 'Unknown':
            i += 1
            continue

        image_url = recommended_anime['Image source']
        if image_url != 'Image preview not available' and image_url.startswith('http'):
            display(Image(url=image_url))
        print(f"English Name: {recommended_anime['English Name']}")
        print(f"Synopsis: {recommended_anime['Synopsis']}")
        print(f"Genres: {recommended_anime['Genres']}")
        print(f"Rating: {recommended_anime['Rating']}")
        print(f"Duration: {recommended_anime['Duration']} min")
        print("-" * 50)

        recommendations += 1
        i += 1  # Move to the next neighbor

    if recommendations < top_n:
        print(f"Only {recommendations} valid recommendations found.")

def load_models():
    global new_anime, nn_model, TfidfVectorizer, tfidf_matrix
    return new_anime, nn_model, TfidfVectorizer, tfidf_matrix

def get_recommendations(anime_title, top_n=20):
    anime_title = anime_title.strip().lower()
    print(f"Searching recommendations for: {anime_title}")

    best_match = process.extractOne(anime_title, new_anime['English Name'])
    print(f"Best match: {best_match}")

    if best_match is None or best_match[1] < 80:
        print("No good match found")
        return []

    anime_index = new_anime[new_anime['English Name'] == best_match[0]].index[0]
    print(f"Anime index: {anime_index}")

    distances, indices = nn_model.kneighbors(tfidf_matrix[anime_index], n_neighbors=top_n+1)

    recommendations = []
    for idx in indices[0]:
        anime_row = new_anime.iloc[idx]
        if anime_row['English Name'] != 'Unknown':
            recommendations.append({
                'English Name': anime_row['English Name'],
                'Image source': anime_row['Image source']
            })

    print(f"Final recommendations: {recommendations}")
    return recommendations